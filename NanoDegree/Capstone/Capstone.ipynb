{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import pandas as pd  # For storing and manipulation of data files\n",
    "import numpy as np  \n",
    "from sklearn.ensemble import RandomForestClassifier # For finding the weights of features\n",
    "import matplotlib.pyplot as plt  # For plotting figures\n",
    "import seaborn as sns # To make figures more clear\n",
    "from sklearn.feature_selection import SelectFromModel # For selecting the important features\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score # metric for model performance\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA EXPLORATION AND PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the training set : 76020 and number of features : 371\n",
      "Number of rows in the testing set  : 75818 and number of features : 370\n"
     ]
    }
   ],
   "source": [
    "# Reading train and test data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print(\"Number of rows in the training set : {} and number of features : {}\".format(train_data.shape[0],train_data.shape[1]))\n",
    "print(\"Number of rows in the testing set  : {} and number of features : {}\".format(test_data.shape[0],test_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and Target variable in the training set are seperated.ID is just the identifiaction number given to a customer,this variable is also extracted in both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing values in Training set 0\n",
      "Number of Missing values in Testing set 0\n"
     ]
    }
   ],
   "source": [
    "# Searching for Missing Data\n",
    "print(\"Number of Missing values in Training set\",train_data.isnull().sum().sum())\n",
    "print(\"Number of Missing values in Testing set\",test_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates no of rows in the train data is : 71213\n",
      "Maximun number in train data : 9999999999.0\n",
      "Minimum amount in train data : -999999.0\n",
      "Maximun number in train data : 22034738.76\n",
      "Minimum amount in train data : -4942.26\n"
     ]
    }
   ],
   "source": [
    "# selecting the train labels\n",
    "train_ID = train_data.ID\n",
    "\n",
    "# Extrating ID and target from the train data and test data\n",
    "train_data = train_data.drop(labels=[\"ID\"],axis = 1).drop_duplicates()\n",
    "print(\"After removing duplicates no of rows in the train data is :\",train_data.shape[0])\n",
    "\n",
    "# Maximum and minimum value in the train data\n",
    "print(\"Maximun number in train data :\",max(train_data.max()))\n",
    "print(\"Minimum amount in train data :\",min(train_data.min()))\n",
    "\n",
    "# Removing these values as they are outliers\n",
    "for feature in train_data.keys():\n",
    "    train_data = train_data[train_data[feature] != -999999.00]\n",
    "    train_data = train_data[train_data[feature] != 9999999999.0]\n",
    "\n",
    "# Maximum and minimum value in the train data after noise removal\n",
    "print(\"Maximun number in train data :\",max(train_data.max()))\n",
    "print(\"Minimum amount in train data :\",min(train_data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_data.TARGET\n",
    "train_features = train_data.drop(labels=[\"TARGET\"],axis = 1)\n",
    "test_ID = test_data.ID\n",
    "test_features = test_data.drop(\"ID\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>7.057100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.759349</td>\n",
       "      <td>33.443582</td>\n",
       "      <td>78.620067</td>\n",
       "      <td>77.067194</td>\n",
       "      <td>127.607221</td>\n",
       "      <td>3.735173</td>\n",
       "      <td>6.847149</td>\n",
       "      <td>0.444831</td>\n",
       "      <td>0.611159</td>\n",
       "      <td>3.319763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151575</td>\n",
       "      <td>7.896149</td>\n",
       "      <td>1.470553</td>\n",
       "      <td>11.001077</td>\n",
       "      <td>8.025597</td>\n",
       "      <td>23.746897</td>\n",
       "      <td>1.490729</td>\n",
       "      <td>42.351595</td>\n",
       "      <td>28.143850</td>\n",
       "      <td>1.169753e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.735876</td>\n",
       "      <td>13.025949</td>\n",
       "      <td>1195.799122</td>\n",
       "      <td>348.882494</td>\n",
       "      <td>563.329251</td>\n",
       "      <td>95.672929</td>\n",
       "      <td>158.821150</td>\n",
       "      <td>31.764236</td>\n",
       "      <td>37.896630</td>\n",
       "      <td>98.060591</td>\n",
       "      <td>...</td>\n",
       "      <td>30.366251</td>\n",
       "      <td>442.177056</td>\n",
       "      <td>118.276828</td>\n",
       "      <td>621.667522</td>\n",
       "      <td>438.724181</td>\n",
       "      <td>1979.705347</td>\n",
       "      <td>132.162255</td>\n",
       "      <td>3348.487651</td>\n",
       "      <td>2039.339273</td>\n",
       "      <td>1.882382e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.574374e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.983727e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227576e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>7331.340000</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>63317.190000</td>\n",
       "      <td>42767.160000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>374947.530000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var3         var15  imp_ent_var16_ult1  \\\n",
       "count  70571.000000  70571.000000        70571.000000   \n",
       "mean       2.759349     33.443582           78.620067   \n",
       "std        9.735876     13.025949         1195.799122   \n",
       "min        0.000000      5.000000            0.000000   \n",
       "25%        2.000000     23.000000            0.000000   \n",
       "50%        2.000000     28.000000            0.000000   \n",
       "75%        2.000000     40.000000            0.000000   \n",
       "max      238.000000    105.000000       135000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             70571.000000             70571.000000   \n",
       "mean                 77.067194               127.607221   \n",
       "std                 348.882494               563.329251   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             70571.000000             70571.000000   \n",
       "mean                  3.735173                 6.847149   \n",
       "std                  95.672929               158.821150   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  \\\n",
       "count             70571.000000             70571.000000       70571.000000   \n",
       "mean                  0.444831                 0.611159           3.319763   \n",
       "std                  31.764236                37.896630          98.060591   \n",
       "min                   0.000000                 0.000000           0.000000   \n",
       "25%                   0.000000                 0.000000           0.000000   \n",
       "50%                   0.000000                 0.000000           0.000000   \n",
       "75%                   0.000000                 0.000000           0.000000   \n",
       "max                6600.000000              6600.000000        8237.820000   \n",
       "\n",
       "           ...       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "count      ...                 70571.000000             70571.000000   \n",
       "mean       ...                     0.151575                 7.896149   \n",
       "std        ...                    30.366251               442.177056   \n",
       "min        ...                     0.000000                 0.000000   \n",
       "25%        ...                     0.000000                 0.000000   \n",
       "50%        ...                     0.000000                 0.000000   \n",
       "75%        ...                     0.000000                 0.000000   \n",
       "max        ...                  7331.340000             50003.880000   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "count             70571.000000            70571.000000   \n",
       "mean                  1.470553               11.001077   \n",
       "std                 118.276828              621.667522   \n",
       "min                   0.000000                0.000000   \n",
       "25%                   0.000000                0.000000   \n",
       "50%                   0.000000                0.000000   \n",
       "75%                   0.000000                0.000000   \n",
       "max               20385.720000            63317.190000   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "count            70571.000000             70571.000000   \n",
       "mean                 8.025597                23.746897   \n",
       "std                438.724181              1979.705347   \n",
       "min                  0.000000                 0.000000   \n",
       "25%                  0.000000                 0.000000   \n",
       "50%                  0.000000                 0.000000   \n",
       "75%                  0.000000                 0.000000   \n",
       "max              42767.160000            438329.220000   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "count             70571.000000            70571.000000   \n",
       "mean                  1.490729               42.351595   \n",
       "std                 132.162255             3348.487651   \n",
       "min                   0.000000                0.000000   \n",
       "25%                   0.000000                0.000000   \n",
       "50%                   0.000000                0.000000   \n",
       "75%                   0.000000                0.000000   \n",
       "max               24650.010000           681462.900000   \n",
       "\n",
       "       saldo_medio_var44_ult3         var38  \n",
       "count            70571.000000  7.057100e+04  \n",
       "mean                28.143850  1.169753e+05  \n",
       "std               2039.339273  1.882382e+05  \n",
       "min                  0.000000  5.163750e+03  \n",
       "25%                  0.000000  6.574374e+04  \n",
       "50%                  0.000000  9.983727e+04  \n",
       "75%                  0.000000  1.227576e+05  \n",
       "max             374947.530000  2.203474e+07  \n",
       "\n",
       "[8 rows x 369 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample structure of the features\n",
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features in the dataset are numerical features.So,there is no need for conversion of categorical data using one hot encoding.\n",
    "But Number of features are too large for such a small dataset. Feature selection has to be performed to extract important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types and count of features :  (array([dtype('int64'), dtype('float64')], dtype=object), array([258, 111]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types and count of features : \",(np.unique(train_features.dtypes,return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for few columns like var38 is so high.There is a huge differences between 75th percentile and max values.\n",
    "To avoid model giving high weitage to large values.we should normalize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize each feature individually\n",
    "normalized_train_data = pd.DataFrame(normalize(train_features,axis=0))\n",
    "normalized_test_data = pd.DataFrame(normalize(test_features,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "      <td>70571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.088535</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.424061</td>\n",
       "      <td>0.135785</td>\n",
       "      <td>0.137023</td>\n",
       "      <td>0.323879</td>\n",
       "      <td>0.262220</td>\n",
       "      <td>0.782083</td>\n",
       "      <td>0.655506</td>\n",
       "      <td>0.316052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908818</td>\n",
       "      <td>0.425626</td>\n",
       "      <td>0.648758</td>\n",
       "      <td>0.383341</td>\n",
       "      <td>0.366890</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>0.702056</td>\n",
       "      <td>0.766035</td>\n",
       "      <td>0.692037</td>\n",
       "      <td>0.374267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  70571.000000  70571.000000  70571.000000  70571.000000  70571.000000   \n",
       "mean       0.001026      0.003508      0.000247      0.000812      0.000832   \n",
       "std        0.003622      0.001366      0.003756      0.003676      0.003671   \n",
       "min        0.000000      0.000524      0.000000      0.000000      0.000000   \n",
       "25%        0.000744      0.002412      0.000000      0.000000      0.000000   \n",
       "50%        0.000744      0.002937      0.000000      0.000000      0.000000   \n",
       "75%        0.000744      0.004195      0.000000      0.000000      0.000000   \n",
       "max        0.088535      0.011013      0.424061      0.135785      0.137023   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  70571.000000  70571.000000  70571.000000  70571.000000  70571.000000   \n",
       "mean       0.000147      0.000162      0.000053      0.000061      0.000127   \n",
       "std        0.003761      0.003761      0.003764      0.003764      0.003762   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.323879      0.262220      0.782083      0.655506      0.316052   \n",
       "\n",
       "           ...                359           360           361           362  \\\n",
       "count      ...       70571.000000  70571.000000  70571.000000  70571.000000   \n",
       "mean       ...           0.000019      0.000067      0.000047      0.000067   \n",
       "std        ...           0.003764      0.003764      0.003764      0.003764   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           0.908818      0.425626      0.648758      0.383341   \n",
       "\n",
       "                363           364           365           366           367  \\\n",
       "count  70571.000000  70571.000000  70571.000000  70571.000000  70571.000000   \n",
       "mean       0.000069      0.000045      0.000042      0.000048      0.000052   \n",
       "std        0.003764      0.003764      0.003764      0.003764      0.003764   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.366890      0.833410      0.702056      0.766035      0.692037   \n",
       "\n",
       "                368  \n",
       "count  70571.000000  \n",
       "mean       0.001987  \n",
       "std        0.003197  \n",
       "min        0.000088  \n",
       "25%        0.001117  \n",
       "50%        0.001696  \n",
       "75%        0.002085  \n",
       "max        0.374267  \n",
       "\n",
       "[8 rows x 369 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the train data is more normalized.\n",
    "normalized_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2b0603510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAEiCAYAAADUPPdrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5A9tzNgWawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2b0ab8650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using adaboost method for exporting important features\n",
    "adc = AdaBoostClassifier(n_estimators=50,random_state=50)\n",
    "adc.fit(normalized_train_data,train_labels)\n",
    "\n",
    "# Extracting features and corresponding weights\n",
    "features = normalized_train_data.columns.values\n",
    "weight_values = adc.feature_importances_\n",
    "\n",
    "# Forming a data fram with features and corresponsding weights.Add sorting them based on weights\n",
    "feature_weights = pd.DataFrame({'features':features,'weights':weight_values})\n",
    "feature_weights.sort_values(['weights'],ascending=False,inplace=True)\n",
    "\n",
    "# Plotting 20 important features with corresponding weights\n",
    "top_20_features = feature_weights.head(20)\n",
    "plt.figure()\n",
    "top_20_features.plot(x =top_20_features.features,y =1, kind='bar',figsize=(10,4),title='Top 20 Important Features');\n",
    "plt.savefig(\"Hello.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2c5859b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAFTCAYAAABvf1buAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlACAAAAYESgBAAAAMCIQAkAAACAkS8QkcQvlN5MEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2b0aab710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plot of top 20 features \n",
    "plt.figure();\n",
    "ax = normalized_train_data[top_20_features.features].plot(kind = 'box',title = \"Box plot of top 20 features\",figsize =(20,5));\n",
    "ax.set_xlabel(\"features\")\n",
    "ax.set_ylabel(\"values after normalization\")\n",
    "plt.savefig(\"Boxplot of 20 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types and count of features :  (array([dtype('float64')], dtype=object), array([20]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types and count of features : \",(np.unique(normalized_train_data[top_20_features.features].dtypes,return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with 95% cumulative weight : 26\n",
      "Shape of train features after future selection : (70571, 26)\n",
      "Shape of test features after future selection:  (75818, 26)\n"
     ]
    }
   ],
   "source": [
    "# Extracting features with overall cumulative weight of 95 percent\n",
    "weights_cumsum = feature_weights.cumsum()\n",
    "index_values = weights_cumsum[weights_cumsum.weights <= 0.95].index.tolist()\n",
    "print(\"Number of features with 95% cumulative weight :\",len(index_values))\n",
    "top_95_percent_train_features = normalized_train_data[normalized_train_data.columns[index_values]]\n",
    "top_95_percent_test_features  = normalized_test_data[normalized_test_data.columns[index_values]]\n",
    "\n",
    "print(\"Shape of train features after future selection :\",top_95_percent_train_features.shape)\n",
    "print(\"Shape of test features after future selection: \",top_95_percent_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default Random Forest Model\n",
    "\n",
    "defaultRF = RandomForestClassifier(random_state=50)\n",
    "defaultRF.fit(normalized_train_data,train_labels)\n",
    "DRF_predictions = defaultRF.predict_proba(normalized_test_data)\n",
    "pd.DataFrame({\"ID\":test_ID.values,\"TARGET\":DRF_predictions[:,1]}).to_csv('submissionDFRandom.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.812484, total= 2.6min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.831738, total= 2.6min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.836059, total= 2.7min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.828894, total= 2.8min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.834319, total= 2.7min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.840990, total= 2.6min\n",
      "[CV] n_estimators=1000, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.835153, total= 2.7min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.865188, total= 2.6min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.849210, total= 2.6min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=13, score=0.824789, total= 2.7min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.828551, total= 3.1min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.831637, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.812524, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.835951, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.833713, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.841379, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=13 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.835714, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.864976, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.849751, total= 3.0min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=13, score=0.824479, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.825245, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.825941, total= 3.2min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.813935, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.821596, total= 3.2min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 19.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=1000, max_depth=20, score=0.822654, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.840113, total= 3.1min\n",
      "[CV] n_estimators=1000, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.832281, total= 3.1min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.855657, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.844922, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1000, max_depth=20, score=0.818095, total= 3.2min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.824951, total= 3.7min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.826487, total= 3.7min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.814214, total= 3.9min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.821717, total= 3.9min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.821987, total= 3.9min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.840558, total= 3.8min\n",
      "[CV] n_estimators=1200, max_depth=20 .................................\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.855460, total= 3.8min\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.831373, total= 3.8min\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.845249, total= 3.4min\n",
      "[CV] .. n_estimators=1200, max_depth=20, score=0.817204, total= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed: 35.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=50,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid=[{'n_estimators': [1000, 1200], 'max_depth': [13, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Model validation\n",
    "# Few parameter values are removed as it would take time to run all the parameters.These parameter values are selected \n",
    "# After long train and errors.\n",
    "rf = RandomForestClassifier(random_state=50)\n",
    "parameters = [{'n_estimators':[1000,1200],'max_depth':[13,20]}]\n",
    "clf = GridSearchCV(rf,cv=10,param_grid=parameters,scoring='roc_auc',verbose=3,n_jobs=4)\n",
    "clf.fit(top_95_percent_train_features,train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=1, oob_score=False, random_state=50,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting parameters of the best estimator\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions of the best model\n",
    "predictions = clf.predict_proba(top_95_percent_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving predictions of best model\n",
    "pd.DataFrame({\"ID\":test_ID.values,\"TARGET\":predictions[:,1]}).to_csv('BestRandomForestModel.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing best model for sensitivity analysis \n",
    "best_rf = RandomForestClassifier(random_state=50 , max_depth=13,n_estimators=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding noise to training data\n",
    "# No of rows in train data\n",
    "no_of_rows = top_95_percent_train_features.shape[0]\n",
    "for feature in top_95_percent_train_features.keys():\n",
    "    std = top_95_percent_train_features[feature].std()\n",
    "    # Adding random number in range of - STD  to STD to 5 different groups of each size 2% for every feature\n",
    "    top_95_percent_train_features[feature][np.random.randint(0,no_of_rows,int(no_of_rows/50))].add(np.random.random_sample()/std)\n",
    "    top_95_percent_train_features[feature][np.random.randint(0,no_of_rows,int(no_of_rows/50))].add(np.random.random_sample()/std)\n",
    "    top_95_percent_train_features[feature][np.random.randint(0,no_of_rows,int(no_of_rows/50))].add(np.random.random_sample()/std)\n",
    "    top_95_percent_train_features[feature][np.random.randint(0,no_of_rows,int(no_of_rows/50))].add(np.random.random_sample()/std)\n",
    "    top_95_percent_train_features[feature][np.random.randint(0,no_of_rows,int(no_of_rows/50))].add(np.random.random_sample()/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1200, n_jobs=1, oob_score=False, random_state=50,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(top_95_percent_train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting predictions of the best model\n",
    "predictions_sensivity = best_rf.predict_proba(top_95_percent_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving predictions of best model after sensitivity test\n",
    "pd.DataFrame({\"ID\":test_ID.values,\"TARGET\":predictions[:,1]}).to_csv('BestRandomForestSensivityModel.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
