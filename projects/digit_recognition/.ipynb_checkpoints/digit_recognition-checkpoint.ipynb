{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing the required modules\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display\n",
    "# from PIL import Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import tensorflow as tf\n",
    "import idx2numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset is downloaded and extracted.\n",
    "# Data is in idx unicode format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (60000, 28, 28) (60000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Readin MNIST data.\n",
    "train_dataset_orig = idx2numpy.convert_from_file('train-images.idx3-ubyte')\n",
    "train_labels_orig =idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "test_dataset_orig = idx2numpy.convert_from_file('t10k-images.idx3-ubyte')\n",
    "test_labels_orig = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')\n",
    "print('Training set', train_dataset_orig.shape, train_labels_orig.shape)\n",
    "print('Test set', test_dataset_orig.shape, test_labels_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are less than 5 numbers to form a 5-digit sequence.\n",
      "Shape of dataset is (15029, 28, 140)\n",
      "There are less than 5 numbers to form a 5-digit sequence.\n",
      "Shape of dataset is (2482, 28, 140)\n"
     ]
    }
   ],
   "source": [
    "# creating sequences of numbers\n",
    "def create_numbers(dataset,labels):\n",
    "    # creating a numpy dataset.\n",
    "    # ndataset will have only 20% size as we are mixing 5 digits and each digit will have 140 width size.\n",
    "    ndataset =  np.ndarray(shape=(int(dataset.shape[0]/3),int(dataset.shape[1]),int(dataset.shape[2]*5)),dtype=np.float32) \n",
    "    # Initializing labels\n",
    "    nlabels = []\n",
    "    \n",
    "    i=0\n",
    "    w=0\n",
    "    # creating a blank image\n",
    "    null_pic = np.zeros(shape=(28,28))\n",
    "    \n",
    "###### Added blank images to create random sequences#######\n",
    "    while True:\n",
    "        try:\n",
    "            # creates random elements in the  range of 2.\n",
    "            random_blanks = random.randint(0,2)\n",
    "            if random_blanks == 0:\n",
    "                temp = np.hstack([dataset[w],dataset[w+1],dataset[w+2],dataset[w+3],dataset[w+4]])\n",
    "                temp_labels = [labels[w],labels[w+1],labels[w+2],labels[w+3],labels[w+4]]\n",
    "            # adding labels to form a 5 digit\n",
    "                w += 5\n",
    "                i += 1\n",
    "            elif random_blanks == 1:\n",
    "                temp = np.hstack([dataset[w],dataset[w+1],dataset[w+2],dataset[w+3],null_pic])\n",
    "                # We are using 10 as a label for blank pic\n",
    "                temp_labels = [labels[w],labels[w+1],labels[w+2],labels[w+3],10]\n",
    "                # adding labels to form a 5 digit\n",
    "                w += 4\n",
    "                i += 1\n",
    "            elif random_blanks == 2:\n",
    "                temp = np.hstack([dataset[w],dataset[w+1],dataset[w+2],null_pic,null_pic])\n",
    "                # coinver to numpy array\n",
    "                temp_labels = [labels[w],labels[w+1],labels[w+2],10,10]\n",
    "                # adding labels to form a 5 digit\n",
    "                w += 3\n",
    "                i += 1\n",
    "                \n",
    "            ndataset[i,:,:] = temp\n",
    "            nlabels.append(temp_labels)\n",
    "        except Exception as e:\n",
    "            print (\"There are less than 5 numbers to form a 5-digit sequence.\")\n",
    "            break;        \n",
    "    ndataset = ndataset[:i,:,:]\n",
    "    print(\"Shape of dataset is {}\".format(ndataset.shape))\n",
    "    return ndataset,np.array(nlabels).astype(int)\n",
    "\n",
    "\n",
    "train_dataset_seq,train_labels_seq = create_numbers(train_dataset_orig,train_labels_orig)\n",
    "test_dataset_seq,test_labels_seq = create_numbers(test_dataset_orig,test_labels_orig)\n",
    "\n",
    "# normalized train dataset\n",
    "train_dataset_nor = train_dataset_seq/256.0 -0.5\n",
    "test_dataset_nor  = test_dataset_seq/256.0 -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (10520, 28, 140, 1) (10520, 52)\n",
      "Validation set (4509, 28, 140, 1) (4509, 52)\n",
      "Test set (2482, 28, 140, 1) (2482, 52)\n"
     ]
    }
   ],
   "source": [
    "# Reformating data so that it's suitable for the tensorflow format (it expects image data to be 3d(cube shape))\n",
    "image_height = 28\n",
    "image_width = 140\n",
    "num_labels = 10 # Without including the null label\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "\n",
    "# Reformating the dataset to make it suitable for the tensor flow\n",
    "def reformat(dataset):\n",
    "    dataset = dataset.reshape((-1, image_height, image_width, num_channels)).astype(np.float32)\n",
    "    return dataset\n",
    "\n",
    "# formatting the datasets\n",
    "train_dataset_for, train_labels_for = reformat(train_dataset_nor),train_labels_seq\n",
    "test_dataset_for,test_labels_for = reformat(test_dataset_nor),test_labels_seq\n",
    "\n",
    "# creating a validation set from training set\n",
    "\n",
    "train_dataset,valid_dataset,train_labels_encode,valid_labels_encode = train_test_split(train_dataset_for,train_labels_for,test_size=0.3,random_state=50)\n",
    "\n",
    "test_dataset,test_labels_encode = test_dataset_for,test_labels_for\n",
    "\n",
    "\n",
    "# one-hot encoding of the dataset.\n",
    "def oneHot(labels):\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    enc.fit(labels)\n",
    "    return enc.transform(labels)\n",
    "\n",
    "train_labels = oneHot(train_labels_encode)\n",
    "valid_labels = oneHot(valid_labels_encode)\n",
    "test_labels = oneHot(test_labels_encode)\n",
    "\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the model\n",
    "def accuracy(predictions, labels):\n",
    "    \n",
    "    # Separating predictions and labels for each separate digit\n",
    "    predictions_digit1 = predictions[:,0:10]\n",
    "    predictions_digit2 = predictions[:,10:20]\n",
    "    predictions_digit3 = predictions[:,20:30]\n",
    "    predictions_digit4 = predictions[:,30:41]\n",
    "    predictions_digit5 = predictions[:,41:52]\n",
    "    \n",
    "    labels_digit1 = labels[:,0:10]\n",
    "    labels_digit2 = labels[:,10:20]\n",
    "    labels_digit3 = labels[:,20:30]\n",
    "    labels_digit4 = labels[:,30:41]\n",
    "    labels_digit5 = labels[:,41:52]\n",
    "    \n",
    "    truth1 = np.argmax(predictions_digit1,axis = 1)==np.argmax(labels_digit1,axis=1)\n",
    "    truth2 = np.argmax(predictions_digit2,axis=1)==np.argmax(labels_digit2,axis=1)\n",
    "    truth3 = np.argmax(predictions_digit3,axis=1)==np.argmax(labels_digit3,axis=1)\n",
    "    truth4 = np.argmax(predictions_digit4,axis=1)==np.argmax(labels_digit4,axis=1)\n",
    "    truth5 = np.argmax(predictions_digit5,axis=1)==np.argmax(labels_digit5,axis=1)\n",
    "    \n",
    "    return (np.sum(np.column_stack([truth1,truth2,truth3,truth4,truth5]).all(axis=1))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convolutional networks of size 4\n",
    "\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 32\n",
    "num_hidden = 512\n",
    "\n",
    "# For representing the computations as graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Making this graph as the default graph\n",
    "with graph.as_default():\n",
    "    # Input data.\n",
    "    \n",
    "    # for storing the input train data(variable size)\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_height, image_width, num_channels))\n",
    "#     tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, num_labels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 52))\n",
    "    # storing validation and test datasets\n",
    "    tf_valid_dataset = tf.constant(valid_dataset,dtype=tf.float32)\n",
    "    tf_test_dataset = tf.constant(test_dataset,dtype=tf.float32)\n",
    "     \n",
    "    # Variables.\n",
    "    \n",
    "    # Building a four layer CNN\n",
    "    \n",
    "    ## FIRST LAYER\n",
    "    # Intiating the input variable weights randomly from normal distribution\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    # Intiating the layer1 biasesa as zeros\n",
    "    layer1_biases = tf.Variable(tf.constant(0.5,shape =(1,depth)))\n",
    "    \n",
    "    # SECOND LAYER\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth,depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    # THRID LAYER\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([int(image_height / 4) * int(image_width / 4) * depth, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    # FOURTH LAYER with 5 logits\n",
    "    logits1_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    logits1_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "       \n",
    "    logits2_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    logits2_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    \n",
    "    logits3_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    logits3_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    \n",
    "    # null pic will add a new label of 10.\n",
    "    logits4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels+1], stddev=0.1))\n",
    "    logits4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels+1])) \n",
    "    \n",
    "    # Null pic will add new label of 10.\n",
    "    logits5_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels+1], stddev=0.1))\n",
    "    logits5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels+1]))\n",
    "\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        conv1 = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "        \n",
    "        conv2 = tf.nn.conv2d(hidden1, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden2 = tf.nn.relu(conv2 + layer2_biases)\n",
    "        \n",
    "        shape = hidden2.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden2, [-1, shape[1] * shape[2] * shape[3]])\n",
    "        hidden3 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        \n",
    "        return [tf.matmul(hidden3,logits1_weights) + logits1_biases,\\\n",
    "                tf.matmul(hidden3,logits2_weights) + logits2_biases,\\\n",
    "                tf.matmul(hidden3,logits3_weights) + logits3_biases,\\\n",
    "                tf.matmul(hidden3,logits4_weights) + logits4_biases,\\\n",
    "                tf.matmul(hidden3,logits5_weights) + logits5_biases\n",
    "                ]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits1,logits2,logits3,logits4,logits5 = model(tf_train_dataset)\n",
    "    \n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits1,labels = tf_train_labels[:,0:10]))+\\\n",
    "    tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits2,labels = tf_train_labels[:,10:20]))+\\\n",
    "    tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits3,labels = tf_train_labels[:,20:30]))+\\\n",
    "    tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits4,labels = tf_train_labels[:,30:41]))+\\\n",
    "    tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits5,labels = tf_train_labels[:,41:52]))\n",
    "    \n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(0.0005).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data\n",
    "    def predictions(x):\n",
    "        return  tf.concat([tf.nn.softmax(logits = x[0]),\\\n",
    "                tf.nn.softmax(logits = x[1]),\\\n",
    "                tf.nn.softmax(logits = x[2]),\\\n",
    "                tf.nn.softmax(logits = x[3]),\\\n",
    "                tf.nn.softmax(logits = x[4])],1)\n",
    "    \n",
    "    train_prediction = predictions(model(tf_train_dataset))\n",
    "    valid_prediction = predictions(model(tf_valid_dataset))\n",
    "    test_prediction = predictions(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 118.473778\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 50: 10.902331\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 100: 12.129419\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 150: 10.986760\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 200: 11.242470\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 250: 10.419225\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 300: 10.385300\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 350: 11.115490\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 400: 9.828760\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 450: 11.307780\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 500: 10.953825\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 550: 10.485626\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 600: 9.963017\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 650: 9.862290\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 700: 11.029321\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 750: 10.271066\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 800: 10.128331\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 850: 10.767591\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 900: 10.463717\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 950: 10.321112\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1000: 10.546557\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1050: 11.058105\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1100: 10.525312\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1150: 10.978075\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1200: 10.325709\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1250: 9.923496\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1300: 10.459400\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1350: 11.189907\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1400: 10.912933\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1450: 10.866409\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1500: 10.139313\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1550: 9.850240\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1600: 10.035725\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1650: 11.743185\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1700: 9.554506\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1750: 10.476517\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1800: 11.236353\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1850: 10.208094\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1900: 10.556886\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 1950: 10.571831\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2000: 11.027110\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2050: 10.205908\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2100: 10.255170\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2150: 10.938779\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2200: 9.488789\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2250: 10.799144\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2300: 9.306526\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2350: 10.757188\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2400: 10.719793\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2450: 10.640355\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2500: 9.917994\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2550: 10.849526\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2600: 10.140571\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2650: 11.926874\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2700: 10.660173\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2750: 9.726042\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2800: 10.684520\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2850: 10.645868\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2900: 11.036852\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 2950: 10.534189\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3000: 10.086273\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3050: 10.297998\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3100: 11.295734\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3150: 10.141989\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3200: 9.534494\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3250: 11.065550\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3300: 10.719007\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3350: 10.558212\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3400: 10.804894\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3450: 10.465085\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3500: 9.831996\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3550: 10.662762\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3600: 10.275784\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3650: 10.417380\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3700: 10.943207\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3750: 10.096858\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3800: 9.241920\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3850: 10.731041\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3900: 10.053008\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 3950: 10.292439\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4000: 10.233810\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4050: 9.959279\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4100: 9.344658\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4150: 9.929438\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4200: 9.391387\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4250: 10.346554\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4300: 9.963455\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4350: 10.406729\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4400: 9.670871\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4450: 9.546721\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4500: 9.114126\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4550: 8.992904\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4600: 9.266907\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4650: 9.162572\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4700: 9.290309\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4750: 9.539062\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4800: 10.567879\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4850: 10.360373\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4900: 9.870340\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 4950: 8.678395\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5000: 9.088332\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5050: 8.804802\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5100: 10.248220\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5150: 9.356349\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5200: 10.227951\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5250: 10.221756\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5300: 9.676096\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5350: 10.771673\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5400: 8.852982\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5450: 8.939746\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5500: 9.479582\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5550: 9.467114\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5600: 9.431713\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5650: 9.050495\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5700: 8.950287\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5750: 9.207374\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5800: 8.398570\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5850: 8.670931\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5900: 8.429131\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 5950: 9.220908\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6000: 9.092560\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6050: 9.668569\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6100: 9.634719\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6150: 8.794960\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6200: 9.902132\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6250: 8.962290\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6300: 10.079551\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6350: 9.354217\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6400: 9.045157\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6450: 7.482728\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6500: 8.214248\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6550: 7.229185\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6600: 7.673330\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6650: 7.725766\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6700: 8.176101\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6750: 7.969191\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6800: 7.632274\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6850: 8.083588\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6900: 8.074499\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 6950: 6.800598\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7000: 7.086324\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7050: 7.165259\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7100: 7.039295\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7150: 7.314684\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7200: 7.931859\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7250: 6.471296\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7300: 4.251620\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7350: 7.703208\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7400: 6.545856\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7450: 8.304592\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7500: 5.389954\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7550: 6.023649\n",
      "Minibatch accuracy: 0.3%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7600: 5.995994\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7650: 7.260103\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7700: 5.988243\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7750: 5.684243\n",
      "Minibatch accuracy: 0.3%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7800: 5.090992\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7850: 8.745325\n",
      "Minibatch accuracy: 0.1%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7900: 4.989532\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 7950: 6.423616\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8000: 5.045807\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8050: 4.560372\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8100: 4.289268\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8150: 5.788735\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8200: 5.223264\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8250: 5.580224\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8300: 3.790149\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8350: 3.976458\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8400: 4.038122\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8450: 5.358274\n",
      "Minibatch accuracy: 0.3%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8500: 3.644480\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8550: 4.020491\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8600: 4.458805\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8650: 4.512097\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8700: 4.352258\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8750: 3.498941\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8800: 4.850542\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8850: 4.963517\n",
      "Minibatch accuracy: 0.2%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8900: 4.594870\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 8950: 3.345298\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9000: 3.255281\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9050: 2.100906\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9100: 2.299980\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9150: 3.185107\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9200: 3.811857\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9250: 3.052141\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9300: 2.578800\n",
      "Minibatch accuracy: 0.4%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9350: 4.203262\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9400: 1.906344\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9450: 1.916898\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9500: 1.955309\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9550: 2.383225\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9600: 2.333986\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9650: 2.450983\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9700: 1.561036\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9750: 1.818807\n",
      "Minibatch accuracy: 0.6%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9800: 1.343162\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9850: 1.127050\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9900: 1.504424\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 9950: 2.407134\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.0%\n",
      "Test accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "len_train_data = train_dataset.shape[0]\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        random_index = [random.randint(0,len_train_data-1) for x in range(batch_size)] \n",
    "        batch_data = train_dataset[random_index, :, :, :]\n",
    "        batch_labels = train_labels[random_index, :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict = feed_dict)\n",
    "        if (step % 50 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "# save the session\n",
    "# tf.train.saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:** \n",
    "I used  notMNIST data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset before formatting :  (32, 32, 3, 73257)\n",
      "Shape of test  dataset before formatting :  (32, 32, 3, 26032)\n",
      "Shape of train labels  before formatting :  (73257, 1)\n",
      "Shape of test  labels  before formatting :  (26032, 1)\n",
      "Shape of train dataset after formatting :  (73257, 32, 32, 3)\n",
      "Shape of test  dataset after formatting :  (26032, 32, 32, 3)\n",
      "Shape of train labels  after formatting :  (73257, 10)\n",
      "Shape of test  labels  after formatting :  (26032, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading and processing datasets\n",
    "\n",
    "train_dataset = (scipy.io.loadmat('train_32x32.mat')['X']).astype('float')\n",
    "train_labels = (scipy.io.loadmat('train_32x32.mat')['y']).astype('float')\n",
    "test_dataset= (scipy.io.loadmat('test_32x32.mat')['X']).astype('float')\n",
    "test_labels = (scipy.io.loadmat('test_32x32.mat')['y']).astype('float')\n",
    "\n",
    "print(\"Shape of train dataset before formatting : \",train_dataset.shape)\n",
    "print(\"Shape of test  dataset before formatting : \",test_dataset.shape)\n",
    "print(\"Shape of train labels  before formatting : \",train_labels.shape)\n",
    "print(\"Shape of test  labels  before formatting : \",test_labels.shape)\n",
    "\n",
    "num_labels = 10\n",
    "def reformat(dataset,labels):\n",
    "    \n",
    "    \n",
    "    # Nomalizing the picture values\n",
    "    dataset = (dataset/256) - 0.5\n",
    "    \n",
    "    # Rearraning dataset to match placeholder shape\n",
    "    dataset = np.array([dataset[:,:,:,x] for x in range(dataset.shape[3])])\n",
    "    \n",
    "    # one hot encoding\n",
    "    labels[labels == 10] = 0\n",
    "    \n",
    "    # Reshaping labels to 1 dimentional array\n",
    "    y = []\n",
    "    for x in range(len(labels)):\n",
    "        y.append(labels[x][0])\n",
    "    labels = np.array(y)\n",
    "    \n",
    "    # One hot encoding\n",
    "    labels = (np.arange(num_labels) == labels[:,None])\n",
    "    \n",
    "    return dataset,labels\n",
    "train_dataset,train_labels = reformat(train_dataset,train_labels)\n",
    "test_dataset ,test_labels  = reformat(test_dataset ,test_labels)\n",
    "\n",
    "print(\"Shape of train dataset after formatting : \",train_dataset.shape)\n",
    "print(\"Shape of test  dataset after formatting : \",test_dataset.shape)\n",
    "print(\"Shape of train labels  after formatting : \",train_labels.shape)\n",
    "print(\"Shape of test  labels  after formatting : \",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reformating data so that it's suitable for the tensorflow format(it expects iamge data to be 3d(cube shape))\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the model\n",
    "def accuracy(predictions, labels):\n",
    "    # getting the percent of how many predictions were correct\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
